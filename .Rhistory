model_prob_urb <- lm(cs_rate ~ urbanicity + year + fips, data=labor_incarceration)
model_prob_urb_p <- plm(cs_rate ~ urbanicity,data=labor_incarceration, index=c("fips","year"), model="within"  )
model_prob_urb <- lm(cs_rate ~ urbanicity + year + fips, data=labor_incarceration)
model_prob_urb_p <- plm(cs_rate ~ urbanicity,data=labor_incarceration, index=c("fips","year"), model="within" , effect="time" )
summary(model_prob_urb_p)
summary(model_prob_urb)
model_prob_urb_p <- plm(cs_rate ~ urbanicity + total_incarceration_rate,data=labor_incarceration, index=c("fips","year"), model="within" , effect="time" )
summary(model_prob_urb_p)
model_prob_urb <- lm(cs_rate ~ urbanicity + year + fips, data=labor_incarceration)
model_prob_urb_p <- plm(cs_rate ~ urbanicity + unemployment_rate +  total_incarceration_rate,data=labor_incarceration, index=c("fips","year"), model="within" , effect="time" )
summary(model_prob_urb_p)
summary(model_prob_urb)
model_prob_urb_p <- plm(cs_rate ~ urbanicity + unemployment_rate +  total_incarceration_rate,data=labor_incarceration, index=c("fips","year"), model="between" , effect="time" )
summary(model_prob_urb_p)
model_prob_urb_p <- plm(cs_rate ~ urbanicity+  total_incarceration_rate,data=labor_incarceration, index=c("fips","year"), model="between" , effect="time" )
summary(model_prob_urb_p)
model_prob_urb_p <- plm(cs_rate ~ urbanicity+  total_incarceration_rate,data=labor_incarceration, index=c("fips","year"), model="within" , effect="time" )
summary(model_prob_urb_p)
model_prob_urb_p <- plm(cs_rate ~ urbanicity+  total_incarceration_rate,data=labor_incarceration, index=c("fips","year"), model="between" , effect="time" )
summary(model_prob_urb_p)
model_prob_urb_p <- plm(cs_rate ~ urbanicity ,data=labor_incarceration, index=c("fips","year"), model="between" , effect="time" )
summary(model_prob_urb_p)
# load packages
if (!require("pacman")) install.packages("pacman")
pacman::p_load(tidyverse, # for most everything
aws.s3, # to connect to our data on AWS
googlesheets4, # to read/write to google sheet
readxl,
RSocrata # for LAPD arrest data
)
# add a used package
library(clipr)
# set correct region for S3
Sys.setenv("AWS_DEFAULT_REGION" = "us-west-1")
# load LA Jails age data since ~2020
age <- read_sheet("https://docs.google.com/spreadsheets/d/1VCC6i4fuEv6T14PRcZBoBs5knsRBzJB8Csjaz6-Hqpc/",
range = "age") %>%
mutate(date = as.Date(date))
gen_death_1999_2020 <- read_sheet("https://docs.google.com/spreadsheets/d/1PiXmB6yV_2zDDnC1Y6NAJ1N0f2A9LYISlij5Y3jVRkM/edit#gid=0",
n_max=3700)
View(gen_death_1999_2020)
gen_death_2020_2023 <- read_sheet("https://docs.google.com/spreadsheets/d/1PiXmB6yV_2zDDnC1Y6NAJ1N0f2A9LYISlij5Y3jVRkM/edit#gid=736298216",
n_max=1012)
View(gen_death_2020_2023)
gen_death_1999_2020 <- read_sheet("https://docs.google.com/spreadsheets/d/1PiXmB6yV_2zDDnC1Y6NAJ1N0f2A9LYISlij5Y3jVRkM/edit#gid=0",
n_max=3699)
gen_death_2018_2023 <- read_sheet("https://docs.google.com/spreadsheets/d/1PiXmB6yV_2zDDnC1Y6NAJ1N0f2A9LYISlij5Y3jVRkM/edit#gid=736298216",
n_max=1012)
View(gen_death_2018_2023)
View(gen_death_2018_2023)
gen_death_1999_2020 <- read_sheet("https://docs.google.com/spreadsheets/d/1PiXmB6yV_2zDDnC1Y6NAJ1N0f2A9LYISlij5Y3jVRkM/edit#gid=0",
n_max=3699, col_types = "cicDcnnnnnnn")
gen_death_1999_2020 <- read_sheet("https://docs.google.com/spreadsheets/d/1PiXmB6yV_2zDDnC1Y6NAJ1N0f2A9LYISlij5Y3jVRkM/edit#gid=0",
n_max=3699, col_types = "ccicDcnnnnnnn")
warnings()
View(gen_death_1999_2020)
View(gen_death_1999_2020)
View(gen_death_1999_2020)
gen_death_1999_2020 <- read_sheet("https://docs.google.com/spreadsheets/d/1PiXmB6yV_2zDDnC1Y6NAJ1N0f2A9LYISlij5Y3jVRkM/edit#gid=0",
n_max=3699, col_types = "ccicicnnnnnnn")
gen_death_2018_2023 <- read_sheet("https://docs.google.com/spreadsheets/d/1PiXmB6yV_2zDDnC1Y6NAJ1N0f2A9LYISlij5Y3jVRkM/edit#gid=736298216",
n_max=1012, col_types = "ccicicnn")
View(gen_death_2018_2023)
View(gen_death_2018_2023)
gen_death_2018_2023 <- read_sheet("https://docs.google.com/spreadsheets/d/1PiXmB6yV_2zDDnC1Y6NAJ1N0f2A9LYISlij5Y3jVRkM/edit#gid=736298216",
n_max=1012, col_types = "ccicicnn")
gen_death_2018_2023 <- read_sheet("https://docs.google.com/spreadsheets/d/1PiXmB6yV_2zDDnC1Y6NAJ1N0f2A9LYISlij5Y3jVRkM/edit#gid=736298216",
n_max=1012, col_types = "ccicicnn", range = "Sheet2")
gen_death_1999_2020 <- read_sheet("https://docs.google.com/spreadsheets/d/1PiXmB6yV_2zDDnC1Y6NAJ1N0f2A9LYISlij5Y3jVRkM/edit#gid=0",
n_max=3699,
col_types = "ccicicnnnnnnn",
range = "Sheet1")
gen_death_2018_2023 <- read_sheet("https://docs.google.com/spreadsheets/d/1PiXmB6yV_2zDDnC1Y6NAJ1N0f2A9LYISlij5Y3jVRkM/edit#gid=736298216",
n_max=1012,
col_types = "ccicicnn",
range = "Sheet2")
gen_death_2018_2023 <- read_sheet("https://docs.google.com/spreadsheets/d/1PiXmB6yV_2zDDnC1Y6NAJ1N0f2A9LYISlij5Y3jVRkM/edit#gid=736298216",
n_max=1012,
col_types = "ccicicnn",
range = "Sheet2") %>%
mutate(`Age Group` = case_when(age <= 25 ~ "18 to 25",
age >= 26 & age <= 34 ~ "26 to 34",
age >= 35 & age <= 39 ~ "35 to 39",
age >= 40 & age <= 44 ~ "40 to 44",
age >= 45 ~ "45 & Over"))
gen_death_2018_2023 <- read_sheet("https://docs.google.com/spreadsheets/d/1PiXmB6yV_2zDDnC1Y6NAJ1N0f2A9LYISlij5Y3jVRkM/edit#gid=736298216",
n_max=1012,
col_types = "ccicicnn",
range = "Sheet2"
.name_repair = tolower(gsub(" ", "_"))) %>%
gen_death_2018_2023 <- read_sheet("https://docs.google.com/spreadsheets/d/1PiXmB6yV_2zDDnC1Y6NAJ1N0f2A9LYISlij5Y3jVRkM/edit#gid=736298216",
n_max=1012,
col_types = "ccicicnn",
range = "Sheet2"
name_repair = tolower(gsub(" ", "_"))) %>%
gen_death_2018_2023 <- read_sheet("https://docs.google.com/spreadsheets/d/1PiXmB6yV_2zDDnC1Y6NAJ1N0f2A9LYISlij5Y3jVRkM/edit#gid=736298216",
n_max=1012,
col_types = "ccicicnn",
range = "Sheet2",
.name_repair = tolower())
gen_death_2018_2023 <- read_sheet("https://docs.google.com/spreadsheets/d/1PiXmB6yV_2zDDnC1Y6NAJ1N0f2A9LYISlij5Y3jVRkM/edit#gid=736298216",
n_max=1012,
col_types = "ccicicnn",
range = "Sheet2",
.name_repair = tolower)
gen_death_2018_2023 <- read_sheet("https://docs.google.com/spreadsheets/d/1PiXmB6yV_2zDDnC1Y6NAJ1N0f2A9LYISlij5Y3jVRkM/edit#gid=736298216",
n_max=1012,
col_types = "ccicicnn",
range = "Sheet2",
.name_repair = tolower, gsub(" ", "_"))
gen_death_2018_2023 <- read_sheet("https://docs.google.com/spreadsheets/d/1PiXmB6yV_2zDDnC1Y6NAJ1N0f2A9LYISlij5Y3jVRkM/edit#gid=736298216",
n_max=1012,
col_types = "ccicicnn",
range = "Sheet2",
.name_repair = tolower,
.name_repair = gsub(" ", "_"))
my_custom_name_repair <- function(nms) tolower(gsub(" ", "_", nms))
gen_death_2018_2023 <- read_sheet("https://docs.google.com/spreadsheets/d/1PiXmB6yV_2zDDnC1Y6NAJ1N0f2A9LYISlij5Y3jVRkM/edit#gid=736298216",
n_max=1012,
col_types = "ccicicnn",
range = "Sheet2",
.name_repair = my_custom_name_repair)
my_custom_name_repair <- function(nms) tolower(gsub(" ", "_", nms),gsub("-", "_", nms))
gen_death_2018_2023 <- read_sheet("https://docs.google.com/spreadsheets/d/1PiXmB6yV_2zDDnC1Y6NAJ1N0f2A9LYISlij5Y3jVRkM/edit#gid=736298216",
n_max=1012,
col_types = "ccicicnn",
range = "Sheet2",
.name_repair = my_custom_name_repair)
my_custom_name_repair <- function(nms) tolower(gsub(" ", "_", "-", "_", nms))
gen_death_2018_2023 <- read_sheet("https://docs.google.com/spreadsheets/d/1PiXmB6yV_2zDDnC1Y6NAJ1N0f2A9LYISlij5Y3jVRkM/edit#gid=736298216",
n_max=1012,
col_types = "ccicicnn",
range = "Sheet2",
.name_repair = my_custom_name_repair)
gen_death_2018_2023 <- read_sheet("https://docs.google.com/spreadsheets/d/1PiXmB6yV_2zDDnC1Y6NAJ1N0f2A9LYISlij5Y3jVRkM/edit#gid=736298216",
n_max=1012,
col_types = "ccicicnn",
range = "Sheet2",
.name_repair = custom_name_repair)
custom_name_repair <- function(nms) tolower(gsub(" ", "_", nms))
gen_death_2018_2023 <- read_sheet("https://docs.google.com/spreadsheets/d/1PiXmB6yV_2zDDnC1Y6NAJ1N0f2A9LYISlij5Y3jVRkM/edit#gid=736298216",
n_max=1012,
col_types = "ccicicnn",
range = "Sheet2",
.name_repair = custom_name_repair)
gen_death_1999_2020 <- read_sheet("https://docs.google.com/spreadsheets/d/1PiXmB6yV_2zDDnC1Y6NAJ1N0f2A9LYISlij5Y3jVRkM/edit#gid=0",
n_max=3699,
col_types = "ccicicnnnnnnn",
range = "Sheet1",
.name_repair = custom_name_repair,
gsub("-", "_"))
# load general mortality by single year of age data
gen_death_1999_2020 <- read_sheet("https://docs.google.com/spreadsheets/d/1PiXmB6yV_2zDDnC1Y6NAJ1N0f2A9LYISlij5Y3jVRkM/edit#gid=0",
n_max=3699,
col_types = "ccicicnnnnnnn",
range = "Sheet1",
.name_repair = custom_name_repair,
gsub("-", "_") nms)
gen_death_2018_2023 <- read_sheet("https://docs.google.com/spreadsheets/d/1PiXmB6yV_2zDDnC1Y6NAJ1N0f2A9LYISlij5Y3jVRkM/edit#gid=736298216",
n_max=1012,
col_types = "ccicicnn",
range = "Sheet2",
.name_repair = custom_name_repair) %>%
mutate(`age_group` = case_when(single_year_ages_code <= 25 ~ "18 to 25",
single_year_ages_code >= 26 & single_year_ages_code <= 34 ~ "26 to 34",
single_year_ages_code >= 35 & single_year_ages_code <= 39 ~ "35 to 39",
single_year_ages_code >= 40 & single_year_ages_code <= 44 ~ "40 to 44",
single_year_ages_code >= 45 ~ "45 & Over"))
library(sf); library(spdep); library(tmap)
library(sf); library(spdep); library(tmap)
setwd("/Users/jkangbrown/Documents/GitHub/when_police_replication")
s = st_read("original_data_collection/statistical_neighborhoods/statistical_neighborhoods.shp")
library(haven)
merged_data_for_analysis <- read_dta("~/Downloads/replication_materials_data/merged_data_for_analysis.dta")
data2 = dplyr::select(data,
neighborhood, week, nh_week, period2, period3, violent, property, crime_assault, crime_mvt)
library(sf); library(spdep); library(tmap)
library(haven)
setwd("/Users/jkangbrown/Documents/GitHub/when_police_replication")
# Add a load command for the Stata data
data <- read_dta("~/Downloads/replication_materials_data/merged_data_for_analysis.dta")
# Point to a complete shape file:
s = st_read("original_data_collection/statistical_neighborhoods/statistical_neighborhoods.shp")
names(s)
names(data)
data2 = dplyr::select(data,
neighborhood, week, nh_week, period2, period3, violent, property, crime_assault, crime_mvt)
data2$NBHD_ID = data2$neighborhood
shape = merge(s, data2, by = "NBHD_ID")
#define neighboring polygons - going w/ queen
nb = poly2nb(shape, queen = T)
#get weights
lw = nb2listw(nb, style="W", zero.policy = T)
#create lagged measures by nhood - https://rpubs.com/erikaaldisa/spatialweights
violent_lag = lag.listw(lw, shape$violent)
lag.list.v = list(shape$NBHD_ID, lag.listw(lw, shape$violent))
lag.res.v = as.data.frame(lag.list.v)
colnames(lag.res.v) = c("NBHD_ID", "lag violent (queen)")
head(lag.res.v)
data = cbind(data, lag.res.v)
property_lag = lag.listw(lw, shape$property)
lag.list.p = list(shape$NBHD_ID, lag.listw(lw, shape$property))
lag.res.p = as.data.frame(lag.list.p)
colnames(lag.res.p) = c("NBHD_ID", "lag property (queen)")
head(lag.res.p)
data = cbind(data, lag.res.p)
assault_lag = lag.listw(lw, shape$crime_assault)
lag.list.a = list(shape$NBHD_ID, lag.listw(lw, shape$crime_assault))
lag.res.a = as.data.frame(lag.list.a)
colnames(lag.res.a) = c("NBHD_ID", "lag assault (queen)")
head(lag.res.a)
data = cbind(data, lag.res.a)
mvt_lag = lag.listw(lw, shape$crime_mvt)
lag.list.m = list(shape$NBHD_ID, lag.listw(lw, shape$crime_mvt))
lag.res.m = as.data.frame(lag.list.m)
colnames(lag.res.m) = c("NBHD_ID", "lag mvt (queen)")
head(lag.res.m)
data = cbind(data, lag.res.m)
save(data, file="~/Downloads/replication_materials_data/replication_data_resubmit.RData")
###PERIODS + CONFROUNDERS W/ VCS
violent_periods_conf_nb_w = glmer.nb (violent ~ period2 + period3 +
accident + total_pop + disadvantage + pct_black + pct_hispanic_any + immigration + prcp + tavg + AQI + open_table + `lag violent (queen)` +
(1 + period2 + period3|neighborhood),
data=data, nAGQ = 0)
#load packages
library (Matrix); library (lme4); library (performance); library (lmerTest)
library (sjstats); library (stargazer); library (tidyverse); library("Hmisc")
library(car)
#get rid of scientific notation
options(scipen = 999)
###PERIODS + CONFROUNDERS W/ VCS
violent_periods_conf_nb_w = glmer.nb (violent ~ period2 + period3 +
accident + total_pop + disadvantage + pct_black + pct_hispanic_any + immigration + prcp + tavg + AQI + open_table + `lag violent (queen)` +
(1 + period2 + period3|neighborhood),
data=data, nAGQ = 0)
summary(violent_periods_conf_nb_w)
BIC(violent_periods_conf_nb_w)
AIC(violent_periods_conf_nb_w)
logLik(violent_periods_conf_nb_w, REML = F)
###PERIODS + CONFOUNDERS + PSTOPS W/ VCS
violent_periods_conf_pstop_nb_w = glmer.nb (violent ~ period2 + period3 +
pstop_wgt_avg_3wk_dev +
accident + total_pop + disadvantage + pct_black + pct_hispanic_any + immigration + prcp + tavg + AQI + open_table + `lag violent (queen)` +
(1 + period2 + period3 + pstop_wgt_avg_3wk_dev|neighborhood),
data=data, family=poisson, nAGQ = 0)
summary(violent_periods_conf_pstop_nb_w)
BIC(violent_periods_conf_pstop_nb_w)
AIC(violent_periods_conf_pstop_nb_w)
logLik(violent_periods_conf_pstop_nb_w, REML = F)
###PERIODS + CONFOUNDERS + VSTOPS W/ VCS
violent_periods_conf_vstop_nb_w = glmer.nb (violent ~ period2 + period3 +
vstop_wgt_avg_3wk_dev +
accident + total_pop + disadvantage + pct_black + pct_hispanic_any + immigration + prcp + tavg + AQI + open_table + `lag violent (queen)` +
(1 + period2 + period3 + vstop_wgt_avg_3wk_dev|neighborhood),
data=data, family=poisson, nAGQ = 0)
summary(violent_periods_conf_vstop_nb_w)
BIC(violent_periods_conf_vstop_nb_w)
AIC(violent_periods_conf_vstop_nb_w)
logLik(violent_periods_conf_vstop_nb_w, REML = F)
###PERIODS + CONFOUNDERS + DARRESTS W/ VCS
violent_periods_conf_darrest_nb_w = glmer.nb (violent ~ period2 + period3 +
arrest_drug_wgt_avg_3wk_dev +
accident + total_pop + disadvantage + pct_black + pct_hispanic_any + immigration + prcp + tavg + AQI + open_table + `lag violent (queen)` +
(1 + period2 + period3 + arrest_drug_wgt_avg_3wk_dev|neighborhood),
data=data, family=poisson, nAGQ = 0)
summary(violent_periods_conf_darrest_nb_w)
BIC(violent_periods_conf_darrest_nb_w)
AIC(violent_periods_conf_darrest_nb_w)
logLik(violent_periods_conf_darrest_nb_w, REML = F)
###PERIODS + CONFOUNDERS + DISARRESTS W/ VCS
violent_periods_conf_disarrest_nb_w = glmer.nb (violent ~ period2 + period3 +
arrest_disorder_wgt_avg_3wk_dev +
accident + total_pop + disadvantage + pct_black + pct_hispanic_any + immigration + prcp + tavg + AQI + open_table + `lag violent (queen)` +
(1 + period2 + period3 + arrest_disorder_wgt_avg_3wk_dev|neighborhood),
data=data, family=poisson, nAGQ = 0)
summary(violent_periods_conf_disarrest_nb_w)
BIC(violent_periods_conf_disarrest_nb_w)
AIC(violent_periods_conf_disarrest_nb_w)
logLik(violent_periods_conf_disarrest_nb_w, REML = F)
#TABLE 1. MAIN TEXT
#PANEL 1 - OLS - MEDIATOR DEVIATIONS AS OUTCOMES
#Pedestrian stops
pstop_confounders = lmer (pstop_wgt_avg_3wk_dev ~ period2 + period3 +
accident + total_pop + disadvantage + pct_black + pct_hispanic_any + immigration + prcp + tavg + AQI + open_table +
(1 + period2 + period3|neighborhood),
data=data)
summary(pstop_confounders)
BIC(pstop_confounders)
AIC(pstop_confounders)
logLik(pstop_confounders, REML = F)
#Vehicle stops
vstop_confounders = lmer (vstop_wgt_avg_3wk_dev ~ period2 + period3 +
accident + total_pop + disadvantage + pct_black + pct_hispanic_any + immigration + prcp + tavg + AQI + open_table +
(1 + period2 + period3|neighborhood),
data=data)
summary(vstop_confounders)
BIC(vstop_confounders)
AIC(vstop_confounders)
logLik(vstop_confounders, REML = F)
#Drug arrests
darrest_confounders = lmer (arrest_drug_wgt_avg_3wk_dev ~ period2 + period3 +
accident + total_pop + disadvantage + pct_black + pct_hispanic_any + immigration + prcp + tavg + AQI + open_table +
(1 + period2 + period3|neighborhood),
data=data)
summary(darrest_confounders)
BIC(darrest_confounders)
AIC(darrest_confounders)
logLik(darrest_confounders, REML = F)
#Disorder arrests
disarrest_confounders = lmer (arrest_disorder_wgt_avg_3wk_dev ~ period2 + period3 +
accident + total_pop + disadvantage + pct_black + pct_hispanic_any + immigration + prcp + tavg + AQI + open_table +
(1 + period2 + period3|neighborhood),
data=data)
summary(disarrest_confounders)
BIC(disarrest_confounders)
AIC(disarrest_confounders)
logLik(disarrest_confounders, REML = F)
#PANEL 3 - PROPERTY COUNT MODELS - NEGATIVE BINOMIAL DIRECT EFFECTS###########################################################################################
###PERIODS + CONFROUNDERS W/ VCS
property_periods_conf_nb_w = glmer.nb (property ~ period2 + period3 +
accident + total_pop + disadvantage + pct_black + pct_hispanic_any + immigration + prcp + tavg + AQI + open_table + `lag property (queen)` +
(1 + period2 + period3|neighborhood),
data=data, nAGQ = 0)
summary(property_periods_conf_nb_w)
BIC(property_periods_conf_nb_w)
AIC(property_periods_conf_nb_w)
logLik(property_periods_conf_nb_w, REML = F)
###PERIODS + CONFOUNDERS + PSTOPS W/ VCS
property_periods_conf_pstop_nb_w = glmer.nb (property ~ period2 + period3 +
pstop_wgt_avg_3wk_dev +
accident + total_pop + disadvantage + pct_black + pct_hispanic_any + immigration + prcp + tavg + AQI + open_table + `lag property (queen)` +
(1 + period2 + period3 + pstop_wgt_avg_3wk_dev|neighborhood),
data=data, family=poisson, nAGQ = 0)
summary(property_periods_conf_pstop_nb_w)
BIC(property_periods_conf_pstop_nb_w)
AIC(property_periods_conf_pstop_nb_w)
logLik(property_periods_conf_pstop_nb_w, REML = F)
###PERIODS + CONFOUNDERS + VSTOPS W/ VCS
property_periods_conf_vstop_nb_w = glmer.nb (property ~ period2 + period3 +
vstop_wgt_avg_3wk_dev +
accident + total_pop + disadvantage + pct_black + pct_hispanic_any + immigration + prcp + tavg + AQI + open_table + `lag property (queen)` +
(1 + period2 + period3 + vstop_wgt_avg_3wk_dev|neighborhood),
data=data, family=poisson, nAGQ = 0)
summary(property_periods_conf_vstop_nb_w)
BIC(property_periods_conf_vstop_nb_w)
AIC(property_periods_conf_vstop_nb_w)
logLik(property_periods_conf_vstop_nb_w, REML = F)
###PERIODS + CONFOUNDERS + DARRESTS W/ VCS
property_periods_conf_darrest_nb_w = glmer.nb (property ~ period2 + period3 +
arrest_drug_wgt_avg_3wk_dev +
accident + total_pop + disadvantage + pct_black + pct_hispanic_any + immigration + prcp + tavg + AQI + open_table + `lag property (queen)` +
(1 + period2 + period3 + arrest_drug_wgt_avg_3wk_dev|neighborhood),
data=data, family=poisson, nAGQ = 0)
summary(property_periods_conf_darrest_nb_w)
BIC(property_periods_conf_darrest_nb_w)
AIC(property_periods_conf_darrest_nb_w)
logLik(property_periods_conf_darrest_nb_w, REML = F)
###PERIODS + CONFOUNDERS + DISARRESTS W/ VCS
property_periods_conf_disarrest_nb_w = glmer.nb (property ~ period2 + period3 +
arrest_disorder_wgt_avg_3wk_dev +
accident + total_pop + disadvantage + pct_black + pct_hispanic_any + immigration + prcp + tavg + AQI + open_table + `lag property (queen)` +
(1 + period2 + period3 + arrest_disorder_wgt_avg_3wk_dev|neighborhood),
data=data, family=poisson, nAGQ = 0)
summary(property_periods_conf_disarrest_nb_w)
BIC(property_periods_conf_disarrest_nb_w)
AIC(property_periods_conf_disarrest_nb_w)
logLik(property_periods_conf_disarrest_nb_w, REML = F)
#Pedestrian stops
pstop_confounders = lmer (pstop_wgt_avg_3wk_dev ~
(1 |neighborhood),
data=data)
summary(pstop_confounders)
logLik(pstop_confounders, REML = F)
performance::icc(pstop_confounders)
#Vehicle stops
vstop_confounders = lmer (vstop_wgt_avg_3wk_dev ~
(1 |neighborhood),
data=data)
summary(vstop_confounders)
logLik(vstop_confounders, REML = F)
performance::icc(vstop_confounders)
#Drug arrests
darrest_confounders = lmer (arrest_drug_wgt_avg_3wk_dev ~
(1 |neighborhood),
data=data)
summary(darrest_confounders)
logLik(darrest_confounders, REML = F)
performance::icc(darrest_confounders)
#Disorder arrests
disarrest_confounders = lmer (arrest_disorder_wgt_avg_3wk_dev ~
(1 |neighborhood),
data=data)
summary(disarrest_confounders)
logLik(disarrest_confounders, REML = F)
performance::icc(disarrest_confounders)
library(sf); library(spdep); library(tmap)
library(haven)
#install.packages("rgeoda")
library(rgeoda)
library(tidyverse)
#open data
setwd ("~/downloads/Replication Materials")
s = st_read("statistical_neighborhoods/statistical_neighborhoods.shp")
s$neighborhood_key = str_replace(s$NBHD_NAME, " - ", "-")
#Create a queen weight matrix with a smaller file.
#this provides an accurate account of neighbors.
## GeoDa
nb_g <- queen_weights(s)
summary(nb_g)
## This R SPDEP analysis
nb_p <- poly2nb(s, queen = T)
# 	save "$denver/jkb_analysis_simplified_spatial_test.dta", replace
data <- read_dta("jkb_analysis.dta")
data_simple <- read_dta("jkb_analysis_simplified_spatial_test.dta")
shp_nb <- distinct_at(s, vars(NBHD_ID, NBHD_NAME, neighborhood_key))
data_nb <- distinct_at(data, vars(neighborhood, neighborhood_key))
shape_test = merge(shp_nb, data_nb, by.x = "neighborhood_key" , by.y = "neighborhood_key")
View(shape_test)
library(sf); library(spdep); library(tmap)
library(haven)
setwd("~/Documents/GitHub/when_police_replication")
# Point to a complete shape file:
s = st_read("original_data_collection/statistical_neighborhoods/statistical_neighborhoods.shp")
# recode the string name to simplify
s$shape_nb_key = str_replace(s$NBHD_NAME, " - ", "-")
shape_merge <-  s %>%
shape_nb_key = str_replace(s$NBHD_NAME, " - ", "-")
shape_merge <-  select(s.shape_nb_key, s.neighborhood)
# Point to a complete shape file:
s = st_read("original_data_collection/statistical_neighborhoods/statistical_neighborhoods.shp")
# recode the string name to simplify
s$shape_nb_key = str_replace(s$NBHD_NAME, " - ", "-")
# rename the numeric identifier to neighborhood
s$neighborhood = NBHD_ID
s$neighborhood = s$NBHD_ID
# simplify file
shape_merge <-  select(s.shape_nb_key, s.neighborhood)
shape_merge <-  select(s$shape_nb_key, s$neighborhood)
library(sf); library(spdep); library(tmap)
library(haven)
setwd("~/Documents/GitHub/when_police_replication")
# Point to a complete shape file:
s = st_read("original_data_collection/statistical_neighborhoods/statistical_neighborhoods.shp")
# recode the string name to simplify
s$shape_nb_key = str_replace(s$NBHD_NAME, " - ", "-")
# rename the numeric identifier to neighborhood
s$neighborhood = s$NBHD_ID
# simplify file
shape_merge <- distinct_at(s, vars(neighborhood, shape_nb_key))
library(sf); library(spdep); library(tmap)
library(haven)
setwd("~/Documents/GitHub/when_police_replication")
# Point to a complete shape file:
s = st_read("original_data_collection/statistical_neighborhoods/statistical_neighborhoods.shp")
# recode the string name to simplify
s$shape_nb_key = str_replace(s$NBHD_NAME, " - ", "-")
# rename the numeric identifier to neighborhood
s$neighborhood = s$NBHD_ID
# simplify file
shape_merge <- distinct_at(s, vars(neighborhood, shape_nb_key))
write_dta("replication_materials/merge_failure_files/shape_merge.dta"
shape_merge,
write_dta(shape_merge,
"/replication_materials/merge_failure_files/shape_merge.dta"
version = 13,
write_dta(
shape_merge,
"~/Documents/GitHub/when_police_replication/replication_materials/merge_failure_files/shape_merge.dta"
version = 13,
write_dta(
shape_merge,
"~/Documents/GitHub/when_police_replication/replication_materials/merge_failure_files/shape_merge.dta",
version = 13,
)
write_dta(
shape_merge,
"replication_materials/merge_failure_files/shape_merge.dta",
version = 13,
)
library(sf); library(spdep);
library(haven)
setwd("~/Documents/GitHub/when_police_replication")
# Point to a complete shape file:
s = st_read("original_data_collection/statistical_neighborhoods/statistical_neighborhoods.shp")
# recode the string name to simplify
s$shape_nb_key = str_replace(s$NBHD_NAME, " - ", "-")
# rename the numeric identifier to neighborhood
s$neighborhood = s$NBHD_ID
# simplify file
shape_merge <- distinct_at(s, vars(neighborhood, shape_nb_key))
write_dta(
shape_merge,
"replication_materials/merge_failure_files/shape_merge.dta",
version = 13,
)
library(sf);
library(haven)
setwd("~/Documents/GitHub/when_police_replication")
# Point to a complete shape file:
s = st_read("original_data_collection/statistical_neighborhoods/statistical_neighborhoods.shp")
# recode the string name to simplify
s$shape_nb_key = str_replace(s$NBHD_NAME, " - ", "-")
# rename the numeric identifier to neighborhood
s$neighborhood = s$NBHD_ID
# simplify file
shape_merge <- distinct_at(s, vars(neighborhood, shape_nb_key))
write_dta(
shape_merge,
"replication_materials/merge_failure_files/shape_merge.dta",
version = 13,
)
source("~/.active-rstudio-document")
